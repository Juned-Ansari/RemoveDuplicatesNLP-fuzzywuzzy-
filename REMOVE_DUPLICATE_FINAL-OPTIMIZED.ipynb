{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Duplicates From the List\n",
    "This algo is used to remove duplicate retailers from the list\n",
    "\n",
    "<img src=\"remove_duplicates.jpg\" width=\"400px\" hieght=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Import Libraries\n",
    "#########\n",
    "import sys  \n",
    "import csv\n",
    "import pymysql\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read StorePArtList with 6 digit pincode ###\n",
    "my_df = pd.read_csv(\"DATA/PR retailers for internal duplication.csv\",dtype=str,low_memory=False)\n",
    "query1 = \"\"\"\n",
    "        select distinct Pincode from my_df where length(Pincode)=6\n",
    "     \"\"\"\n",
    "df_pincode = ps.sqldf(query1, locals())\n",
    "query1 = \"\"\"\n",
    "        SELECT Id as Id,lower(RetailerName) as StorePartyName,(lower(coalesce(Address1,'')) || ' ' || lower(coalesce(Address2,'')))as Address,lower(City) as City,lower(Pincode) as Pincode FROM my_df\n",
    "        WHERE Pincode in (select Pincode from df_pincode)\n",
    "     \"\"\"\n",
    "my_df = ps.sqldf(query1, locals())\n",
    "\n",
    "final_merged_list = pd.DataFrame(columns=['Id','StorePartyName','Address','City','Pincode','StorePartyName_removed_unwanted_words','RetailerId','AddressPercentage'])\n",
    "for idx1, r1 in df_pincode.iterrows():\n",
    "    print(r1['Pincode'])\n",
    "    query2 = \"\"\"\n",
    "            SELECT * FROM my_df WHERE lower(Pincode) = '{}'\n",
    "         \"\"\".format(r1['Pincode'])\n",
    "    df_retailers = ps.sqldf(query2, locals())\n",
    "\n",
    "    #Remove Un-wanted Words from RetailerName \n",
    "    df_retailers['RetailerName_removed_unwanted_words'] = df_retailers['StorePartyName'].str.replace('medical and general stores|&|medigen|medgen|gen stores|gen store|genstores|med & gen|medical  gen|medi  gen|pharmacuticals|pharmacutical|distributors|distributor|agencies|agency|medicals|medical|meidcal|madical|medicos|medicose|medisales|medicare|stores|stotes|stors|stors|store|hospitals|hospital|surgicals|surgical|pharmaceuticals|pharmaceutical|pharmacies|pharmacy|pharma|chemists|chemist|druggists|medicines|medicine|medicos|medico|generals|general|genral|ganeral|generel|enterprises|enterprise|drugs |drug |drugist|druggist|centre|center|corner|shopee|wholsale|retail|cosmetics|healthcare|house|points|point|pvt|ltd| medi | med | gen | med | and', '')\n",
    "    df_retailers\n",
    "\n",
    "    try:\n",
    "        Exact_Percentage = 0\n",
    "        lst_df = pd.DataFrame(columns=['Id','StorePartyName','Address','City','Pincode','StorePartyName_removed_unwanted_words','RetailerId','AddressPercentage'])\n",
    "        tmp_df = pd.DataFrame(columns=['AddressPercentage','RetailerId','Id'])\n",
    "        c=1\n",
    "        for index1, row1 in df_retailers.iterrows():\n",
    "            print(c)\n",
    "            c= c + 1\n",
    "            Id = str(row1['Id'])\n",
    "            StorePartyName = (re.sub('[^a-zA-Z ]','',str(row1['StorePartyName'])).strip())\n",
    "            StorePartyName_removed_unwanted_words = (re.sub('[^a-zA-Z ]','',str(row1['RetailerName_removed_unwanted_words'])).strip())\n",
    "            StorePartyAddress = str(row1['Address']).strip()        \n",
    "            StorePartyPincode = re.sub('[^0-9 ]','',str(row1['Pincode'])).strip()\n",
    "            StorePartyCity = (re.sub('[^a-zA-Z ]','',str(row1['City'])).strip())\n",
    "            if(len(lst_df)>0):\n",
    "                if len(StorePartyName_removed_unwanted_words)>2:\n",
    "                    a = lst_df[(lst_df['StorePartyName']!=\"\") & (lst_df['StorePartyName_removed_unwanted_words'].str.startswith(StorePartyName_removed_unwanted_words[:2]))]\n",
    "                    if(len(a)>0):\n",
    "                        df_retailer_mapping = (a[((a['StorePartyName_removed_unwanted_words'].str.contains(StorePartyName_removed_unwanted_words)) | (a.apply(lambda row: fuzz.token_set_ratio(row['StorePartyName_removed_unwanted_words'], StorePartyName_removed_unwanted_words), axis=1) > 92))])\n",
    "                    else:\n",
    "                        df_retailer_mapping = pd.DataFrame()\n",
    "                else:\n",
    "                    a = lst_df[(lst_df['StorePartyName']!=\"\") & (lst_df['StorePartyName'].str.startswith(StorePartyName[:2]))]\n",
    "                    if(len(a)>0):\n",
    "                        df_retailer_mapping = (a[((a['StorePartyName'].str.contains(StorePartyName)) | (a.apply(lambda row: fuzz.token_set_ratio(row['StorePartyName'], StorePartyName), axis=1) > 92))])\n",
    "                    else:\n",
    "                        df_retailer_mapping = pd.DataFrame()\n",
    "            else:\n",
    "                df_retailer_mapping = pd.DataFrame()\n",
    "\n",
    "            #print(df_retailer_mapping)\n",
    "\n",
    "            if(len(df_retailer_mapping)>0):\n",
    "                for index, row in df_retailer_mapping.iterrows():\n",
    "                    Address_Ratio = fuzz.token_set_ratio(re.sub(' +', ' ', row['Address']),re.sub(' +', ' ', StorePartyAddress))\n",
    "                    #print(\"Address Ration:\",Address_Ratio)\n",
    "                    if Address_Ratio >= 50:\n",
    "                        ######Create Dataframe        #########\n",
    "                        tmp_df.loc[index,'Id'] = Id\n",
    "                        tmp_df.loc[index,'RetailerId'] = str(row['Id'])\n",
    "                        tmp_df.loc[index,'AddressPercentage'] = Address_Ratio\n",
    "\n",
    "\n",
    "                if (len(tmp_df)>0):            \n",
    "                    query = \"SELECT * from tmp_df order by AddressPercentage desc limit 1\"\n",
    "                    tmp_final = ps.sqldf(query, locals())\n",
    "                    for index_s, row_max_s in tmp_final.iterrows():\n",
    "                        lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(row_max_s['RetailerId']),'AddressPercentage':str(row_max_s['AddressPercentage'])}, ignore_index=True)\n",
    "\n",
    "                    tmp_df = tmp_df.iloc[0:0]\n",
    "                    tmp_final = tmp_final.iloc[0:0]\n",
    "                else:\n",
    "                    #print(\"else:\")\n",
    "                    RetailerId = \"\"\n",
    "                    lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(RetailerId),'AddressPercentage':fuzz.token_set_ratio(row['Address'],StorePartyAddress)}, ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                #print(\"main else:\")\n",
    "                RetailerId = \"\"\n",
    "                lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(RetailerId),'AddressPercentage':''}, ignore_index=True)\n",
    "\n",
    "\n",
    "        #print(lst_df)\n",
    "        #lst_df.to_csv('/home/juned/PythonWork/Mapping/DATA/Mobile Number Retailer List_DuplicateRemoved_final-'+r1['Pincode']+'.csv', header=True, index=False)\n",
    "        final_merged_list = final_merged_list.append(lst_df)\n",
    "        lst_df = lst_df.iloc[0:0]\n",
    "        #final_merged_list.to_csv('/home/juned/PythonWork/Mapping/DATA/Mobile Number Retailer List_DuplicateRemoved_Ubuntu-2000.csv', header=True, index=False)\n",
    "    except IndexError:\n",
    "        #  Python 3\n",
    "        print(\"Error on line {}\".format(sys.exc_info()[-1].tb_lineno))                \n",
    "\n",
    "final_merged_list.to_csv('/home/juned/PythonWork/Mapping/DATA/PR retailers for internal duplication-6digit.csv', header=True, index=False,quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Read StorePArtList non-6 digit pincode ###\n",
    "my_df = pd.read_csv(\"DATA/PR retailers for internal duplication.csv\",dtype=str,low_memory=False)\n",
    "query1 = \"\"\"\n",
    "        select distinct Pincode from my_df where length(Pincode)=6\n",
    "     \"\"\"\n",
    "df_pincode = ps.sqldf(query1, locals())\n",
    "\n",
    "query1 = \"\"\"\n",
    "        SELECT Id as Id,lower(RetailerName) as StorePartyName,(lower(coalesce(Address1,'')) || ' ' || lower(coalesce(Address2,'')))as Address,lower(City) as City,lower(Pincode) as Pincode FROM my_df\n",
    "        WHERE Pincode not in (select Pincode from df_pincode)\n",
    "     \"\"\"\n",
    "df_retailers = ps.sqldf(query1, locals())\n",
    "\n",
    "# Remove Un-wanted Words from RetailerName \n",
    "df_retailers['RetailerName_removed_unwanted_words'] = df_retailers['StorePartyName'].str.replace('medical and general stores|&|medigen|medgen|gen stores|gen store|genstores|med & gen|medical  gen|medi  gen|pharmacuticals|pharmacutical|distributors|distributor|agencies|agency|medicals|medical|meidcal|madical|medicos|medicose|medisales|medicare|stores|stotes|stors|stors|store|hospitals|hospital|surgicals|surgical|pharmaceuticals|pharmaceutical|pharmacies|pharmacy|pharma|chemists|chemist|druggists|medicines|medicine|medicos|medico|generals|general|genral|ganeral|generel|enterprises|enterprise|drugs |drug |drugist|druggist|centre|center|corner|shopee|wholsale|retail|cosmetics|healthcare|house|points|point|pvt|ltd| medi | med | gen | med | and', '')\n",
    "df_retailers\n",
    "\n",
    "my_df_6digit = pd.read_csv(\"DATA/PR retailers for internal duplication-6digit.csv\",dtype=str,low_memory=False)\n",
    "# my_df_6digit     \n",
    "lst_df = pd.DataFrame(columns=['Id','StorePartyName','Address','City','Pincode','StorePartyName_removed_unwanted_words','RetailerId','AddressPercentage'])\n",
    "lst_df = my_df_6digit\n",
    "# lst_df #640569\n",
    "try:\n",
    "    Exact_Percentage = 0\n",
    "    \n",
    "    tmp_df = pd.DataFrame(columns=['AddressPercentage','RetailerId','Id'])\n",
    "    c=1\n",
    "    for index1, row1 in df_retailers.iterrows():\n",
    "        print(c)\n",
    "        c= c + 1\n",
    "        Id = str(row1['Id'])\n",
    "        StorePartyName = (re.sub('[^a-zA-Z ]','',str(row1['StorePartyName'])).strip())\n",
    "        StorePartyName_removed_unwanted_words = (re.sub('[^a-zA-Z ]','',str(row1['RetailerName_removed_unwanted_words'])).strip())\n",
    "        StorePartyAddress = str(row1['Address']).strip()        \n",
    "        StorePartyPincode = re.sub('[^0-9 ]','',str(row1['Pincode'])).strip()\n",
    "        StorePartyCity = (re.sub('[^a-zA-Z ]','',str(row1['City'])).strip())\n",
    "        if(len(lst_df)>0):\n",
    "            if len(StorePartyName_removed_unwanted_words)>2:\n",
    "                a = lst_df[(lst_df['StorePartyName']!=\"\") & (lst_df['Id']!=Id) & (lst_df['StorePartyName_removed_unwanted_words'].str.startswith(StorePartyName_removed_unwanted_words[:2]))]\n",
    "                if(len(a)>0):\n",
    "                    df_retailer_mapping = (a[((a['StorePartyName_removed_unwanted_words'].str.contains(StorePartyName_removed_unwanted_words)) | (a.apply(lambda row: fuzz.token_set_ratio(row['StorePartyName_removed_unwanted_words'], StorePartyName_removed_unwanted_words), axis=1) > 92))])\n",
    "                else:\n",
    "                    df_retailer_mapping = pd.DataFrame()\n",
    "            else:\n",
    "                if len(StorePartyName)<=1:\n",
    "                    df_retailer_mapping = pd.DataFrame()\n",
    "                else:\n",
    "                    a = lst_df[(lst_df['StorePartyName']!=\"\") & (lst_df['Id']!=Id) & (lst_df['StorePartyName'].str.startswith(StorePartyName[:2]))]\n",
    "                    if(len(a)>0):\n",
    "                        df_retailer_mapping = (a[((a['StorePartyName'].str.contains(StorePartyName)) | (a.apply(lambda row: fuzz.token_set_ratio(row['StorePartyName'], StorePartyName), axis=1) > 92))])\n",
    "                    else:\n",
    "                        df_retailer_mapping = pd.DataFrame()\n",
    "        else:\n",
    "            df_retailer_mapping = pd.DataFrame()\n",
    "\n",
    "        #print(df_retailer_mapping)\n",
    "\n",
    "        if(len(df_retailer_mapping)>0):\n",
    "            for index, row in df_retailer_mapping.iterrows():\n",
    "                if len(StorePartyAddress)>6:\n",
    "                    Address_Ratio = fuzz.token_set_ratio(re.sub(' +', ' ', row['Address']),re.sub(' +', ' ', StorePartyAddress))\n",
    "                    #print(\"Address Ration:\",Address_Ratio)\n",
    "                    if Address_Ratio >= 85:\n",
    "                        ######Create Dataframe        #########\n",
    "                        tmp_df.loc[index,'Id'] = Id\n",
    "                        tmp_df.loc[index,'RetailerId'] = str(row['Id'])\n",
    "                        tmp_df.loc[index,'AddressPercentage'] = Address_Ratio\n",
    "\n",
    "\n",
    "            if (len(tmp_df)>0):            \n",
    "                query = \"SELECT * from tmp_df order by AddressPercentage desc limit 1\"\n",
    "                tmp_final = ps.sqldf(query, locals())\n",
    "                for index_s, row_max_s in tmp_final.iterrows():\n",
    "                    lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(row_max_s['RetailerId']),'AddressPercentage':str(row_max_s['AddressPercentage'])}, ignore_index=True)\n",
    "\n",
    "                tmp_df = tmp_df.iloc[0:0]\n",
    "                tmp_final = tmp_final.iloc[0:0]\n",
    "            else:\n",
    "                #print(\"else:\")\n",
    "                RetailerId = \"\"\n",
    "                lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(RetailerId),'AddressPercentage':fuzz.token_set_ratio(row['Address'],StorePartyAddress)}, ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            #print(\"main else:\")\n",
    "            RetailerId = \"\"\n",
    "            lst_df = lst_df.append({'Id':str(row1['Id']),'StorePartyName': str(row1['StorePartyName']),'Address':str(row1['Address']),'City':str(row1['City']),'Pincode':str(row1['Pincode']),'StorePartyName_removed_unwanted_words':str(StorePartyName_removed_unwanted_words),'RetailerId':str(RetailerId),'AddressPercentage':''}, ignore_index=True)\n",
    "\n",
    "\n",
    "    #print(lst_df)\n",
    "    lst_df.to_csv('/home/juned/PythonWork/Mapping/DATA/PR retailers for internal duplication-all-final.csv', header=True, index=False,quoting=csv.QUOTE_ALL)\n",
    "#     lst_df = lst_df.iloc[0:0]\n",
    "except IndexError:\n",
    "    #  Python 3\n",
    "    print(\"Error on line {}\".format(sys.exc_info()[-1].tb_lineno))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to merge multiple csv files into one\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"DATA/today\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"/home/juned/PythonWork/Mapping/DATA/today/combined_csv.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
